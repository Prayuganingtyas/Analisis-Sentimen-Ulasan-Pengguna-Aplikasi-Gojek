{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "0tk981Q0EAZX"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('gojek_reviews.csv')\n",
        "data = data.dropna(subset=['content'])"
      ],
      "metadata": {
        "id": "Emu1kD93qvaA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labeling Sentimen dan Membagi Data ke Training & Testing"
      ],
      "metadata": {
        "id": "Alf57lzSqwhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6tmR9HdFDiS7"
      },
      "outputs": [],
      "source": [
        "def map_sentiment(score):\n",
        "    if score <= 2:\n",
        "        return 'negatif'\n",
        "    elif score == 3:\n",
        "        return 'netral'\n",
        "    else:\n",
        "        return 'positif'\n",
        "\n",
        "data['sentiment'] = data['score'].apply(map_sentiment)\n",
        "\n",
        "X = data['content']\n",
        "y = data['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenisasi dan Padding Teks Review untuk Input Model Deep Learning"
      ],
      "metadata": {
        "id": "M-de7izWrC01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=50000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_length = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "w0Mwrdmyltux"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding Label Sentimen"
      ],
      "metadata": {
        "id": "Dqoktx9-rTWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train_enc = to_categorical(le.fit_transform(y_train))\n",
        "y_test_enc = to_categorical(le.transform(y_test))"
      ],
      "metadata": {
        "id": "38ae0MUalxPh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping untuk Menghindari Overfitting saat Training Model"
      ],
      "metadata": {
        "id": "mR0Qhs9qrZf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "c-5KMCc6l1g0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skema 1 - CNN + LSTM"
      ],
      "metadata": {
        "id": "kS9tOnPenYWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(input_dim=50000, output_dim=128, input_length=max_length))\n",
        "model1.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model1.add(MaxPooling1D(pool_size=2))\n",
        "model1.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history1 = model1.fit(X_train_pad, y_train_enc,\n",
        "                      epochs=10,\n",
        "                      batch_size=128,\n",
        "                      validation_data=(X_test_pad, y_test_enc),\n",
        "                      callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oyUufi3Ecvi",
        "outputId": "ae5badfa-fe8c-4770-dc19-603a860bd1e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 412ms/step - accuracy: 0.4107 - loss: 1.0607 - val_accuracy: 0.6433 - val_loss: 0.8653\n",
            "Epoch 2/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 402ms/step - accuracy: 0.6411 - loss: 0.8613 - val_accuracy: 0.7137 - val_loss: 0.6813\n",
            "Epoch 3/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 404ms/step - accuracy: 0.7147 - loss: 0.7105 - val_accuracy: 0.7290 - val_loss: 0.6505\n",
            "Epoch 4/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 385ms/step - accuracy: 0.7383 - loss: 0.6299 - val_accuracy: 0.8373 - val_loss: 0.4417\n",
            "Epoch 5/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 431ms/step - accuracy: 0.8446 - loss: 0.4278 - val_accuracy: 0.8893 - val_loss: 0.3355\n",
            "Epoch 6/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 401ms/step - accuracy: 0.8742 - loss: 0.3661 - val_accuracy: 0.9040 - val_loss: 0.2974\n",
            "Epoch 7/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 402ms/step - accuracy: 0.8915 - loss: 0.3361 - val_accuracy: 0.9037 - val_loss: 0.2791\n",
            "Epoch 8/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - accuracy: 0.9031 - loss: 0.3057 - val_accuracy: 0.9217 - val_loss: 0.2459\n",
            "Epoch 9/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 402ms/step - accuracy: 0.9324 - loss: 0.2307 - val_accuracy: 0.9597 - val_loss: 0.1745\n",
            "Epoch 10/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 384ms/step - accuracy: 0.9563 - loss: 0.1762 - val_accuracy: 0.9497 - val_loss: 0.1809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skema 2 - BiLSTM"
      ],
      "metadata": {
        "id": "kfUPMkCVmffR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Embedding(input_dim=50000, output_dim=128, input_length=max_length),\n",
        "    Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history2 = model2.fit(X_train_pad, y_train_enc, epochs=10, batch_size=128, validation_data=(X_test_pad, y_test_enc), callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX6rVo-eEV1H",
        "outputId": "1eb5ca3f-4b3b-4698-92ad-099bf13afa23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 644ms/step - accuracy: 0.5529 - loss: 0.9526 - val_accuracy: 0.8477 - val_loss: 0.4376\n",
            "Epoch 2/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 636ms/step - accuracy: 0.8938 - loss: 0.3418 - val_accuracy: 0.9677 - val_loss: 0.0956\n",
            "Epoch 3/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 635ms/step - accuracy: 0.9692 - loss: 0.1010 - val_accuracy: 0.9887 - val_loss: 0.0418\n",
            "Epoch 4/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 641ms/step - accuracy: 0.9817 - loss: 0.0612 - val_accuracy: 0.9807 - val_loss: 0.0386\n",
            "Epoch 5/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 695ms/step - accuracy: 0.9842 - loss: 0.0574 - val_accuracy: 0.9913 - val_loss: 0.0305\n",
            "Epoch 6/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 616ms/step - accuracy: 0.9857 - loss: 0.0485 - val_accuracy: 0.9920 - val_loss: 0.0286\n",
            "Epoch 7/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 705ms/step - accuracy: 0.9900 - loss: 0.0363 - val_accuracy: 0.9910 - val_loss: 0.0260\n",
            "Epoch 8/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 649ms/step - accuracy: 0.9874 - loss: 0.0403 - val_accuracy: 0.9913 - val_loss: 0.0280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skema 3 - CNN + BiLSTM"
      ],
      "metadata": {
        "id": "P6nzAi3Hngny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Embedding(input_dim=50000, output_dim=128, input_length=max_length))\n",
        "model3.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history3 = model3.fit(X_train_pad, y_train_enc,\n",
        "                      epochs=10,\n",
        "                      batch_size=128,\n",
        "                      validation_data=(X_test_pad, y_test_enc),\n",
        "                      callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWZ6GEXNX6Fe",
        "outputId": "0c85066f-1234-410a-9b5b-148a4008127c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 592ms/step - accuracy: 0.5763 - loss: 0.9098 - val_accuracy: 0.8847 - val_loss: 0.3682\n",
            "Epoch 2/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 573ms/step - accuracy: 0.9336 - loss: 0.2320 - val_accuracy: 0.9793 - val_loss: 0.0709\n",
            "Epoch 3/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 597ms/step - accuracy: 0.9790 - loss: 0.0791 - val_accuracy: 0.9867 - val_loss: 0.0431\n",
            "Epoch 4/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 600ms/step - accuracy: 0.9852 - loss: 0.0437 - val_accuracy: 0.9877 - val_loss: 0.0367\n",
            "Epoch 5/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 568ms/step - accuracy: 0.9871 - loss: 0.0411 - val_accuracy: 0.9920 - val_loss: 0.0253\n",
            "Epoch 6/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 562ms/step - accuracy: 0.9889 - loss: 0.0324 - val_accuracy: 0.9907 - val_loss: 0.0254\n",
            "Epoch 7/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 583ms/step - accuracy: 0.9891 - loss: 0.0322 - val_accuracy: 0.9910 - val_loss: 0.0274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skema 4 - Logistic Regression"
      ],
      "metadata": {
        "id": "yp0Y4GByoEs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf3 = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf3 = tfidf3.fit_transform(X_train)\n",
        "X_test_tfidf3 = tfidf3.transform(X_test)\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train_tfidf3, y_train)\n",
        "lr_preds = lr_model.predict(X_test_tfidf3)\n",
        "print(\"Akurasi Logistic Regression:\", accuracy_score(y_test, lr_preds))\n",
        "print(classification_report(y_test, lr_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBcYxS46EXzH",
        "outputId": "76ea8573-b340-4064-c1d7-a3e754e205d3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Logistic Regression: 0.9813333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.98      1.00      0.99      1192\n",
            "      netral       0.99      0.95      0.97       611\n",
            "     positif       0.98      0.98      0.98      1197\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.98      0.98      0.98      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skema 5 - Naive Bayes"
      ],
      "metadata": {
        "id": "TZ-Uto5zoJMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "nb_preds = nb_model.predict(X_test_tfidf)\n",
        "print(\"Akurasi Naive Bayes:\", accuracy_score(y_test, nb_preds))\n",
        "print(classification_report(y_test, nb_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b8sLTtpEZOb",
        "outputId": "3b344c65-2570-4757-9ff2-d4387e35fb16"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Naive Bayes: 0.9383333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.89      0.99      0.94      1192\n",
            "      netral       0.99      0.83      0.91       611\n",
            "     positif       0.96      0.94      0.95      1197\n",
            "\n",
            "    accuracy                           0.94      3000\n",
            "   macro avg       0.95      0.92      0.93      3000\n",
            "weighted avg       0.94      0.94      0.94      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menyimpan Tokenizer dan Label Encoder ke File untuk Inference Model"
      ],
      "metadata": {
        "id": "Ob1ENgjIs9Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)"
      ],
      "metadata": {
        "id": "_QnCiNNMHfA0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.save('best_sentiment_model2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeK5uGp9Vmh8",
        "outputId": "a789e3c2-aaec-46af-a6b8-521968feadf1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KESIMPULAN\n",
        "\n",
        "- Model terbaik secara performa akurasi dan generalisasi adalah BiLSTM dan CNN-BiLSTM.\n",
        "\n",
        "- Logistic Regression masih sangat kompetitif, dengan akurasi mendekati model deep learning, cocok untuk deployment cepat.\n",
        "\n",
        "- Naive Bayes cocok digunakan sebagai baseline awal, tapi tidak unggul dibanding model lain."
      ],
      "metadata": {
        "id": "2DLdRMQU20Jg"
      }
    }
  ]
}